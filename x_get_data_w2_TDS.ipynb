{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "x_get_data_w2_TDS.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO/qB/9gM9eOyWC9w2mhR4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shailesh0209/x_tools_in_ds_dipoma-iitm/blob/main/x_get_data_w2_TDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L2.2: Get the data-Nominatim Open Street Maps"
      ],
      "metadata": {
        "id": "NwaFIOpj-RWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping using Geocoding API of Open Street Maps(OSM)\n",
        "We would be using the Nominatim API to scrape geocoding imformation of any open ended address text using Python"
      ],
      "metadata": {
        "id": "vALaMfUqA6sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no need to install these if using Google Colab\n",
        "!pip install geopandas\n",
        "!pip install geopy"
      ],
      "metadata": {
        "id": "ZudQeA60_gM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nominatim api\n",
        "from geopy.geocoders import Nominatim"
      ],
      "metadata": {
        "id": "OqJfQRvb_gJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# activate nominatim geocoder\n",
        "locator = Nominatim ()\n",
        "# type any address text\n",
        "location = locator.geocode(\"Champ de Mars, Paris, France\")\n"
      ],
      "metadata": {
        "id": "HggGLzirAEKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print latitude and longitude of the address \n",
        "print(\"Latitude={}, Longitude={}\".format(location.latitude, location.longitude))"
      ],
      "metadata": {
        "id": "BtT0t8xyAEH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the API output has multiple other details as a json like altitude, latitude\n",
        "# longitude, correct raw address, etc.\n",
        "# printing all the information\n",
        "\n",
        "location.raw, location.point, location.longitude, location.latitude, location.altitude, location.address"
      ],
      "metadata": {
        "id": "FScdhBsLTI46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# typing another address \n",
        "location2 = locator.geocode(\"IIT Madras\")"
      ],
      "metadata": {
        "id": "vXMF4ctVUD50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location2.raw, location2.point, location2.longitude, location2.latitude, location2.altitude, location2.address"
      ],
      "metadata": {
        "id": "ekOWSIV7Ufp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L2.3 Get the data BBC Weather location service\n"
      ],
      "metadata": {
        "id": "_NWBitIz9t2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n0Uibg6iYWzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A tutorial to scrape the location ID of any city in BBC Weather\n",
        "\n",
        "Thsi code snippet takes city name as input and it hits the BBC Weather API with a request for location ID. This location ID is used as input in the next part of the code to scrape weather forecast for the city using this location ID.\n",
        "\n",
        "Web scraping might not be legal always. It is a good idea to check the terms of the website you plan to scrape before proceeding. Also, if your code requests a url from a server multiple times, it is a good practice to either cache your requests, o insert a timed delay between consecutive requests."
      ],
      "metadata": {
        "id": "fMGzX4t5YShT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import requests  # to get the webpage\n",
        "import json      # to convert API  to json format\n",
        "\n",
        "from urllib.parse import urlencode\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re        # regular expressio operators\n"
      ],
      "metadata": {
        "id": "bpMA_ZngYQrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_city = \"New York\"\n",
        "location_url = 'https://locator-service.api.bcci.co.uk/locations?' + urlencode({\n",
        "                'api_key': 'AGbFAKx58hyjQScCXIYrxuEwJh2W2cmv',\n",
        "                's': test_city,\n",
        "                'stack': 'aws',\n",
        "                'locale': 'en',\n",
        "                'filter': 'international',\n",
        "                'place-types': 'settlement,airport, district',\n",
        "                'order': 'importance',\n",
        "                'a': 'true',\n",
        "                'format': 'json'\n",
        "                })\n",
        "location_url"
      ],
      "metadata": {
        "id": "6lm4KalkYQoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = requests.get(location_url).json()\n",
        "result"
      ],
      "metadata": {
        "id": "-eFa2f5VYQlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print locationid\n",
        "result['response']['results']['results'][0]['id']"
      ],
      "metadata": {
        "id": "NbDF3sBNYQiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating a function to output location id by taking any city name as input."
      ],
      "metadata": {
        "id": "uzQOl9xvjlwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getlocid(city):\n",
        "    city = city.lower() # convert city name to lowercase to standardize format\n",
        "    # Convert into an API call using URL encoding\n",
        "    location_url = 'https://locator-services.api.bcci.co.uk/locations?' + urlencode({\n",
        "        'api_key': 'AGbFAKx58hyjQScCXIYrxuEwJh2W2cmv',\n",
        "        's': city,\n",
        "        'stack': 'aws',\n",
        "        'locale': 'en',\n",
        "        'filter': 'international',\n",
        "        'place-types': 'settlement, airport,district',\n",
        "        'order': 'true',\n",
        "        'format': 'json'\n",
        "    })\n",
        "    result = requests.get(location_url).json()\n",
        "    locid = result['response']['results']['results'][0]['id']\n",
        "    return locid"
      ],
      "metadata": {
        "id": "HdFs7V6VYQfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getlocid('Toronto')"
      ],
      "metadata": {
        "id": "h5RzUsfflIOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L2.4 Get the data-Scraping with Excel"
      ],
      "metadata": {
        "id": "_3Wqe2SU-RSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Paf1MNlemMy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U0_3Rv54mMtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iEvAwvP1mMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AxepI2MWmMgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L2.5 Get the data-Scraping with Python"
      ],
      "metadata": {
        "id": "R3qcNzeb-RPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WEB Scrapping IMDB\n",
        "\n",
        "In this exercise we'll look at scraping data from IMDB. Our goal is to convert the top 250 list of movies in IMDB intoa tabular form using Python. This data can then be used for further analysis."
      ],
      "metadata": {
        "id": "k_61RVfNGFzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: Import Necessary Libraries"
      ],
      "metadata": {
        "id": "zgyG6eNwtbYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests # to access website\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DZIi0TVqGFSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Load the webpage"
      ],
      "metadata": {
        "id": "v9DbE6xRugGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(\"https://www.imdb.com/chart/top/\")\n",
        "\n",
        "# Convert to a beautiful soup object\n",
        "soup = bs(r.content)\n",
        "\n",
        "# Print out HTML\n",
        "Contents = soup.prettify()"
      ],
      "metadata": {
        "id": "_7YhBOD_GByR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Creating empty list"
      ],
      "metadata": {
        "id": "nntWLGRDvAdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_title = []\n",
        "movie_year = []\n",
        "movie_rating = []"
      ],
      "metadata": {
        "id": "KKRSzVJ2GBuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Extract HTML tag contents"
      ],
      "metadata": {
        "id": "mjgkNUWZwpDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_table = soup.find(class_=\"chart full-width\")"
      ],
      "metadata": {
        "id": "-dJw5tUkGBrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_titlecolumn= imdb_table.find_all(class_=\"titleColumn\")"
      ],
      "metadata": {
        "id": "ORdSncZQ0uP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratingscolumn = imdb_table.find_all(class_=\"ratingColumn imdbRating\")"
      ],
      "metadata": {
        "id": "FcwRW2aM08aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in movie_titlecolumn:\n",
        "    title = row.a.text # tag content extraction\n",
        "    movie_title.append(title)\n",
        "movie_title"
      ],
      "metadata": {
        "id": "F1r8Qg7p1LnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in movie_titlecolumn:\n",
        "    year = row.span.text # tag content extraction # gives text contain inside span tag\n",
        "    movie_year.append(year)\n",
        "movie_year"
      ],
      "metadata": {
        "id": "bAqmCtcP1dYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in movie_ratingscolumn:\n",
        "    rating = row.strong.text # tag content extraction\n",
        "    movie_rating.append(rating)\n",
        "movie_rating"
      ],
      "metadata": {
        "id": "quuCXsSF3PYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Create DataFrame"
      ],
      "metadata": {
        "id": "zguvRjTO3o1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_df = pd.DataFrame({'Movie Title': movie_title, 'Year of Release': movie_year, 'IMDB Rating': movie_rating})\n",
        "movie_df"
      ],
      "metadata": {
        "id": "dQbc_gxh3oR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L2.6: Get the data-Wikimedia"
      ],
      "metadata": {
        "id": "pNG1pf2j-y9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L2.7:Get the data-Scrape BBC weather with Python"
      ],
      "metadata": {
        "id": "GZH4yeek--Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L2.8: Get the data-Scraping PDFs"
      ],
      "metadata": {
        "id": "CjiqhibQ_F2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GA2"
      ],
      "metadata": {
        "id": "orUfXEZC_Ma7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k3VEQpz_9_Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31LhgcS59SEJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}